
## 基本信息:
姓名: 段佳伟

性别: 男

出生年月: 1991-11-20

联系电话: 15150545149

邮箱: 731014656@qq.com

GitHub: http://github.com/blankrain

微信: liss5945


## 教育信息:
毕业院校: 西北农林科技大学

院校标签: `诚朴勇毅` `农科城` `985院校` `杨凌` `西北地区`  `终南山` 周 后稷(ji)  `老子` 李世民 `隋文帝`

专业: 地理信息系统

专业标签: `GIS` GPS 地图 北斗 地理 导航 `计算机` 测绘 城市规划 `地理分析` 戴克斯图拉 高斯 国土

受教育时间: 2009-2013

## 工作信息:
- 岗位: 软件开发工程师
  
  公司: 南京苏宁易购
  
  地点: 南京
  
  供职时间: 2013-2015


- 岗位: 软件开发工程师
  
  公司: 北京邮政实业集团

  地点: 北京
  
  供职时间: 2015-2017

## 项目经验及个人成长轨迹:

- 新手试驾
    我是野路子程序员,玩编程,纯粹出于兴趣.感觉这玩意,好玩,有意思.大学期间学了VB,数据库,Java. 剩下的就自己捉摸.
    2013年毕业签苏宁,入职前有三个月的企业内部培训,巩固基础吧.
    我永远记得那个夜晚,我,禹神,老谢在讨论完一个业务逻辑后,禹神在他那台老台式机上码出那一串代码.那一刻我感觉自己打通了任督二脉.
    然后在入职的半年内,功力大增.
    再然后,不小心获得了苏宁svn管理员权限,可读写大部分项目代码.有种一不小心进了藏书阁的错觉.结合苏宁内部Wiki,通读了苏宁在那个时期的大部分源码.了解了其当时的一些技术细节.

    在苏宁任职期间,写的大都是业务逻辑.
    技术上比较简单,都是基于spring的增删改查.简单示意图如下:
        ```
        前端(html,js) -> 业务逻辑(Java,spring,freemarker) -> 数据(db2,redis)
        ```
    一般是由视觉的同事提供HTML文件,我拿到后,自己调整HTML结构,改成freemarker模板文件,自己补充完成页面元素需要响应的事件及其他业务逻辑.
    完成后端Java的业务逻辑开发,自己测通前后端,如有需要,再配合测试人员设计设计压测场景. 工作流基本就这样.

    这段经历我有个总结:
        **保持好奇**
     要对周围的事物留心,要对它们感兴趣,要对关着的门随手推一把,看是不是真的关上了. 如果当初不是蒙出SVN管理员密码,我哪有机会接触那么多项目.

    在苏宁任职期间,有两个东西可以拿出来讲一讲.
    1. 数据的压缩与解压缩
    比如这么一堆数字:
    [
        125717244,124634652,105087000,105087001,105087002,107158806,125042197,
        127813174,127928893,127928915,102428961,102428962,104993435,105086997,
        105806551,124336959,125002716,126627101,125007334,105737403
    ]
    要求无损且尽量短
    我自己捉摸了两天,采用了混搭的方法.前八位用映射法编码,后1位连续起来用另一种算法编码.(专业术语实在想不起来了,其思路就是a->a aa->a2 aaaaa->a5)
    映射法就是一个两位的数字会映射到一位的字母上.比如 12 -> x .
    我这套算法针对上面的数据是有固定压缩率的.不管怎样分布的数据,压缩率在44%~55%之间.
    
    2. 接口限流开关
    背景是这样的,我们有个系统给周边几个系统提供数据服务.一遇到大促,怕自己系统被周边系统拖垮.业务人员提了个"弃车保帅"的需求.
    如果周边系统,压力过大,我们这边系统可有选择的对其进行拒绝服务.(意思很明确,你反正要挂了,就不要拉着我一块挂.但我又不忍心抛弃你,所以,有选择的拒绝你)
    我开发了一个Servlet过滤器,可拦截到所有的服务,然后,在里面添加了拦截逻辑.
    我的过滤器代码不多,可以实现针对某个数据服务的完全拒绝服务,随机拒绝服务,指定机器拒绝服务,指定时间段拒绝服务等多项可组合的拒绝服务功能.
    当然,后来他们拒绝了我的开发方案.认为影响过大风险过高,然后采取了一种我不欣赏的方法完成了相对而言较局限的功能.

    收获:
    "纸上得来终觉浅,觉知此事要躬行",我最大的收获是,我心里如果有一段逻辑,我可以用Java表达出来.也就是,先不论好坏,我可以写出代码来.
    这是我这段工作经历中最大的收获,也是我最早的收获.

- 独狼行
    我因为个人原因离开了苏宁.一个是失恋.另一个是我想自己做点事情.在我处的那段时间,苏宁氛围略保守,可以守成,难以开拓.不过还是很优秀的.
    我来到了北京.在这里我折腾了很多事情.我入职的单位是北京邮政实业集团. 中国邮政底下的一个子公司.它底下有五个二级公司十几个乱七八糟的三级公司.
    背景是,新上任的领导要上软件,走数据营销路线.大背景是,要信息化,互联网+.大大背景是,国企改革.大大大背景是坚持改革开放一百年.

    我干的第一件事是,阿里云上买了七八台服务器,买域名,上Nginx,布VPN,配防火墙,装数据库,做应急备份.
    一个中小企业的IT系统我搭建好了.
    收获就是,云还是蛮方便的.
    这些好像属于运维的职责范围,我没有搞过运维.感谢谷歌,现学现卖,我就成了一条运维狗.

    第二件事情是,上业务软件.根据业务情况,先后上了U8财务软件,思源物业软件,元动汽修软件,CRM客户管理软件,帆软报表软件,微商户,美好生活社区O2O软件.
    跟各路软件商打交道,从接洽到签合同到试运行到验收.(全程我在参与,但不是我一个人)
    最大的收获: 我开始知道代码到底可以值多钱. 我之前觉得写代码是一件很轻松简单的事情,而且脑袋里第一印象是免费.并没有意识到一个功能一行语句到底可以值多钱.这段工作经历让我发现,原来代码是很贵的.


    第三件事,我负责开发数据接口,连通各个业务系统，建造一条信息高速公路,并且得搞数据分析,为业务决策提供数据支持.
    数据接口开发,我数据库用了MySql,Java 框架换成Spring Boot. Spring Web那套太慢了.
    我需要快速开发.就选择了基于Spring的Spring Boot来开发.
    我虽然有好几台服务器,但是那是生产系统.在开发过程中,我需要开发环境和测试环境.机器有限,我回收了一台旧电脑,装上Linux,Docker跑起来.
    解决了我没有开发环境和测试环境的问题. 然后顺带了解学习了一下Docker相关的技术.

    我开发的前两个数据接口,很简单,都是WebService的形式来调用就行.HTTP POST个JSON或者XML,自己实现一些简单的业务逻辑就可以搞定了.
    后面的数据接口,就有些难度.
    最主要的难度在业务系统是买的第三方公司的. 没有数据接口,没有代码,没有数据字典. 我能掌控的,只有正在运行的二进制文件和数据库.
    老实讲,费了老劲了. 从各个层次开代理抓包,非法手段反编译二进制文件,看着表名和字段名猜它的真实含义,然后设计实验验证自己的猜测假设. 最后,总结规律.
    这是一个由模糊到清晰的过程. 我最大的收获是,要平心静气,三十年如一日,再没有头绪,不要急,再一脸懵逼也不要懵.
    坚持不懈,所有绕在眼前的雾霾都会散开.总之,不急不燥不慌,耗一耗,坚持坚持,大部分问题可以解决.(当然,里面也有我耗了好久最后也没有解决的.)

    这里我讲一个项目.
    我下属的某二级公司,它有个业务,分散在北京城,大概十几个点.每个点都有个业务系统,但是是单机版的. 它需要将所有点的数据汇总起来,出报表,做分析.
    它这十几个点,网络状况差,每个点的PC硬件配置也低,而且并不会同时都在线,每天都有不开张的. 针对这种情况,我设计开发了一个数据汇总工具.
    结构大概是这样的:
        ```
            C(n) -MQ-> S -> Analysis
        ```
    C代表着这些站点, 它们每个点都会安装一个我写的客户端. 这个客户端会开机自启,连接我配置的一个MQ,从里面取属于自己的消息.然后执行任务,返回结果到MQ.
    S代表着我的数据收集器,它监听着十几个站点的返回队列,收到消息会入库. 
    Analysis是会根据汇总后的数据,计算生成需要的业务报表.
    做这个项目的时候,我先是去各个点做了一个简单调研.然后,dump了个数据库,回家猜表名猜字段,猜了大概一周.哪里取数大致清楚了.然后就开始开发.

    调研不够深入,第一版开发的时候,没有考虑到网速及上线情况,用的HTTP来通讯,结果失败率很高.然后做了调整,我底层的通讯换成MQ了. 用的是Apache的ActiveMQ.

    在同步数据的过程里,我自己开发了一个调度器,它会定时往对应的队列派发提取数据的消息. 
    因为任务可能会失败,数据会有偏差,我又开发了个校验数据准确性的工具.
    要同步的数据,有好多不同的逻辑,我第一次开发的时候是硬编码,第二次是复制粘贴,第三四次,我忍住冲动,继续复制粘贴.第五次的时候,就把它重构了
    ,搞了一个更通用的,可配置的.

    我自己用freemarker配合xml解析,做了一个类似mybatis的工具渲染SQL语句.

    整个项目我最大的感受是,代码是演化的. 复杂的高级的功能,都是从基本的需求一步一步成长出来的. 
    另外,学习最快的方式是,在用中学,在学中用.边用边学,边学边用.
    最后,百度真的不行,开发必须得谷歌.

    数据分析
    有了原始基础数据,我们要对数据进行加工转换,最后展示出我们想要的数据.
    Java不擅长处理数据. 我自学了Clojure,一门基于JVM的Lisp方言. 
    它处理数据很方便.数据解构,函数式,lazy集合.这些让我在处理数据的时候得心应手.

    我用clojure写过一个爬虫,对方业务系统没有数据导出或数据接口之类的东西. 我通过浏览器抓包,模拟登陆,然后爬取我需要的数据. 最后存储到数据库,做分析展示用.

    在另一个开发爬虫的过程中,我自己编码,写了一个破解第一代的验证码的程序. 验证码也是发展了好几代了.我只能破第一代.
    思路是切割字符串,做个样本库,然后计算相似度.有种朴素贝叶斯分类的味道. 
    这个程序我写的蛮奇葩的,用Java写的.我大量的使用了数组,自己计算下标.一气呵成.初次编译运行,数组越界的异常都没抛.也是挺神的.
    计算相似度,我的算法类似余弦函数.逐像素对比,统计出一样的和不一样的个数,进行一次除法运算,得到一个结果. 排序后,取相似度最高的作为识别值.
    这个验证码程序,我识别率100%.
